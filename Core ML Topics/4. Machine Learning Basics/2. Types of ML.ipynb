{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Types of Machine Learning\n",
    "1. Supervised Learning\n",
    "2. Unsupervised Learning\n",
    "3. Reinforcement Learning\n",
    "4. Semi-supervised Learning\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0bd7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Supervised Learning:\n",
    "- In supervised learning, we have a dataset that contains both input data and the corresponding output labels.\n",
    "- The goal is to learn a mapping from inputs to outputs using this labeled data.\n",
    "- The model is trained on this labeled data, and once trained, it can make predictions on new, unseen data.\n",
    "- Examples include classification and regression tasks.\n",
    "- Common algorithms: Linear Regression, Logistic Regression, Decision Trees, Random Forests, Support Vector\n",
    "Machines, Neural Networks, Ridge and Lasso, ElasticNet, Xgbboost.\n",
    "- Libraries: scikit-learn, TensorFlow, Keras, PyTorch.\n",
    "\n",
    "When to use classification vs regression:\n",
    "- Classification is used when the output variable is categorical (e.g., spam vs. not spam).\n",
    "- Regression is used when the output variable is continuous (e.g., predicting house prices).\n",
    "- In terms of dependent and independent variables which one is which:\n",
    "    - Dependent variable: The output variable we are trying to predict (e.g., price of a house).\n",
    "    - Independent variable: The input features used to make predictions (e.g., size of the house, number of bedrooms).\n",
    "\n",
    "- Classification example: Predicting whether an email is spam or not.\n",
    "- Regression example: Predicting the price of a house based on its features.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification types:\n",
    "1. Binary Classification: Two classes (e.g., spam vs. not spam).\n",
    "2. Multi-class Classification: More than two classes (e.g., classifying images of animals into categories like cat, dog, bird).\n",
    "3. Multi-label Classification: Each instance can belong to multiple classes (e.g., tagging an image with multiple labels like \"outdoor\", \"sunny\").\n",
    "- Multi-class vs. Multi-label: \n",
    "    Multi-class has one label per instance, while multi-label allows multiple labels per instance.\n",
    "    - Example of multi-class classification: Classifying handwritten digits (0-9).\n",
    "    - Example of multi-label classification: Tagging an image with multiple labels (e.g., \"outdoor\", \"sunny\").\n",
    "\n",
    "- Example of binary classification: Predicting whether a customer will churn or not.\n",
    "\n",
    "Classification Algorithms:\n",
    "1. Logistic Regression: Used for binary classification problems.\n",
    "2. Decision Trees: Tree-like model used for both classification and regression tasks.\n",
    "3. Random Forest: Ensemble method that combines multiple decision trees for better accuracy.\n",
    "4. Support Vector Machines (SVM): Finds the optimal hyperplane to separate classes.\n",
    "5. Neural Networks: Deep learning models that can learn complex patterns in data.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae954cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Unsupervised Learning:\n",
    "- In unsupervised learning, we have a dataset without labeled output data.\n",
    "- The goal is to find patterns or structures in the data without any prior knowledge of the output.\n",
    "- Common tasks include clustering and dimensionality reduction.\n",
    "- Examples include clustering algorithms like K-means, hierarchical clustering, and dimensionality reduction techniques like PCA (Principal Component Analysis).\n",
    "- Libraries: scikit-learn, TensorFlow, Keras, PyTorch.\n",
    "\n",
    "- Clustering example: Grouping customers based on purchasing behavior.\n",
    "- Dimensionality reduction example: Reducing the number of features in a dataset while preserving important\n",
    "information.\n",
    "- Clustering vs. Dimensionality Reduction:\n",
    "    - Clustering groups similar data points together, while dimensionality reduction reduces the number of features\n",
    "    in the dataset.\n",
    "    - Example of clustering: Grouping customers based on their purchasing behavior.\n",
    "    - Example of dimensionality reduction: Reducing the number of features in a dataset while preserving important\n",
    "    information.\n",
    "\n",
    "- Clustering algorithms:\n",
    "    1. K-means: Partitions data into K clusters based on similarity.\n",
    "    2. Hierarchical Clustering: Builds a hierarchy of clusters using a tree-like structure.\n",
    "    3. DBSCAN: Density-based clustering algorithm that groups together points that are close to each other.\n",
    "    4. Gaussian Mixture Models (GMM): Probabilistic model that assumes data points are generated from a mixture of\n",
    "        Gaussian distributions.\n",
    "    5. Agglomerative Clustering: Hierarchical clustering method that starts with individual points and merges\n",
    "        them into clusters.\n",
    "    6. Mean Shift: Non-parametric clustering algorithm that finds dense regions in the data.\n",
    "    \n",
    "- Dimensionality reduction algorithms:\n",
    "    1. PCA (Principal Component Analysis): Reduces dimensionality by projecting data onto the directions of maximum variance.\n",
    "    2. t-SNE (t-distributed Stochastic Neighbor Embedding): Non-linear dimensionality reduction technique for visualizing high-dimensional data.\n",
    "    3. UMAP (Uniform Manifold Approximation and Projection): Non-linear dimensionality reduction technique\n",
    "        that preserves both local and global structure.\n",
    "    4. LDA (Linear Discriminant Analysis): Reduces dimensionality while preserving class separability.\n",
    "    5. ICA (Independent Component Analysis): Separates a multivariate signal into additive, independent components.\n",
    "    6. Autoencoders: Neural networks used for unsupervised learning of efficient representations.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff41b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reinforcement Learning:\n",
    "- In reinforcement learning, an agent learns to make decisions by interacting with an environment.\n",
    "- The agent receives feedback in the form of rewards or penalties based on its actions.\n",
    "- The goal is to learn a policy that maximizes the cumulative reward over time.\n",
    "- Common algorithms include Q-learning, Deep Q-Networks (DQN), and Proximal Policy Optimization (PPO).\n",
    "- Libraries: OpenAI Gym, TensorFlow, Keras, PyTorch.\n",
    "- Reinforcement learning example: Training a robot to navigate a maze by rewarding it for reaching the goal and penalizing it for hitting walls.\n",
    "- Reinforcement learning vs. supervised learning:\n",
    "    - Reinforcement learning learns from interactions with the environment, while supervised learning learns from labeled data.\n",
    "    - Example of reinforcement learning: Training a robot to navigate a maze by rewarding it for reaching the goal and penalizing it for hitting walls.\n",
    "- Example of supervised learning: Predicting house prices based on features like size and location.\n",
    "\n",
    "- Reinforcement learning vs. unsupervised learning:\n",
    "    - Reinforcement learning learns from interactions with the environment, while unsupervised learning finds patterns in unlabeled data.\n",
    "    - Example of reinforcement learning: Training a robot to navigate a maze by rewarding it for reaching the goal and penalizing it for hitting walls.\n",
    "    - Example of unsupervised learning: Grouping customers based on purchasing behavior without labeled data.\n",
    "\n",
    "- Reinforcement learning vs. semi-supervised learning:\n",
    "    - Reinforcement learning learns from interactions with the environment, while semi-supervised learning uses a small amount of labeled data along with a large amount of unlabeled data.\n",
    "    - Example of reinforcement learning: Training a robot to navigate a maze by rewarding it for reaching the goal and penalizing it for hitting walls.\n",
    "    - Example of semi-supervised learning: Using a small set of labeled images to train a model that can classify a larger set of unlabeled images.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
