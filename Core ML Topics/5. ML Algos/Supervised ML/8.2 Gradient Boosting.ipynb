{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gradient Boosting :\n",
    "\n",
    "Definition:\n",
    "- Gradient Boosting is a powerful ensemble machine learning technique that builds models sequentially, \n",
    "    where each new model attempts to correct the errors of the previous ones. \n",
    "- It combines multiple weak learners, typically decision trees, to create a strong predictive model. \n",
    "- The key idea is to optimize a loss function by adding models that minimize the \n",
    "    residual errors of the combined model.\n",
    "\n",
    "Key Features:\n",
    "- used for both regression and classification tasks.\n",
    "- It uses a gradient descent algorithm to minimize the loss function.\n",
    "- Each new model is trained on the residuals of the previous models, \n",
    "    allowing it to focus on the areas where the previous models performed poorly.\n",
    "- It can handle various types of data, including numerical and categorical features.\n",
    "- Gradient Boosting can be sensitive to overfitting, especially with deep trees, \n",
    "    so regularization techniques like learning rate and tree depth control are often applied.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5d2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Steps in Gradient Boosting:\n",
    "1. Initialize the model with a constant value (e.g., the mean of the target variable).\n",
    "2. For each iteration:\n",
    "   a. Compute the residuals (errors) of the current model.\n",
    "   b. Fit a new weak learner (e.g., decision tree) to the residuals.\n",
    "   c. Update the model by adding the predictions of the new weak learner, scaled by a learning rate.\n",
    "3. Repeat until a stopping criterion is met (e.g., a maximum number of iterations or convergence).\n",
    "4. Make predictions using the final model.\n",
    "\n",
    "Here formula:\n",
    "a. Learning Rate:\n",
    "- The learning rate (often denoted as \"η\") is a hyperparameter that controls the contribution of each weak learner to the final model.\n",
    "- It is a value between 0 and 1, where a smaller learning rate means that each weak learner has a smaller impact on the final prediction.\n",
    "- The formula for updating the model with a new weak learner is:\n",
    "    F(x) = F(x) + η * h(x)\n",
    "    \n",
    "    where:\n",
    "    - F(x) is the current model's prediction.\n",
    "    - η is the learning rate.\n",
    "    - h(x) is the prediction of the new weak learner.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39390b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Difference with AdaBoost:\n",
    "- AdaBoost (Adaptive Boosting) and Gradient Boosting are both ensemble learning techniques, \n",
    "    but they differ in their approach to combining weak learners.\n",
    "- AdaBoost focuses on adjusting the weights of misclassified instances, \n",
    "    while Gradient Boosting minimizes the residuals of the combined model using gradient descent.\n",
    "- AdaBoost typically uses a fixed learning rate and combines weak learners in a sequential manner, \n",
    "    while Gradient Boosting allows for more flexibility in the learning rate and can use different loss functions.\n",
    "- AdaBoost is often simpler and faster to implement, while Gradient Boosting can be more powerful and flexible,\n",
    "    but may require more careful tuning of hyperparameters.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bec3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "#https://www.kaggle.com/datasets/susant4learning/holiday-package-purchase-prediction?resource=download&select=Travel.csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289e6037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0   NaN     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0        Single            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0        Single            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'Travel.xls')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c3d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                    0\n",
       "ProdTaken                     0\n",
       "Age                         226\n",
       "TypeofContact                25\n",
       "CityTier                      0\n",
       "DurationOfPitch             251\n",
       "Occupation                    0\n",
       "Gender                        0\n",
       "NumberOfPersonVisiting        0\n",
       "NumberOfFollowups            45\n",
       "ProductPitched                0\n",
       "PreferredPropertyStar        26\n",
       "MaritalStatus                 0\n",
       "NumberOfTrips               140\n",
       "Passport                      0\n",
       "PitchSatisfactionScore        0\n",
       "OwnCar                        0\n",
       "NumberOfChildrenVisiting     66\n",
       "Designation                   0\n",
       "MonthlyIncome               233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caec574c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      2916\n",
       "Female    1972\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Gender'].apply(lambda x:'Female' if x=='Fe Male' else x)\n",
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43bc779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaritalStatus\n",
       "Married      2340\n",
       "Unmarried    1598\n",
       "Divorced      950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MaritalStatus'] = df['MaritalStatus'].replace({'Single':'Unmarried'})\n",
    "df['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9328048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 4.62357 % missing values\n",
      "TypeofContact 0.51146 % missing values\n",
      "DurationOfPitch 5.13502 % missing values\n",
      "NumberOfFollowups 0.92062 % missing values\n",
      "PreferredPropertyStar 0.53191 % missing values\n",
      "NumberOfTrips 2.86416 % missing values\n",
      "NumberOfChildrenVisiting 1.35025 % missing values\n",
      "MonthlyIncome 4.76678 % missing values\n"
     ]
    }
   ],
   "source": [
    "## Checking missing values\n",
    "\n",
    "feature_with_na = [features for features in df.columns if df[features].isnull().sum() > 0]\n",
    "for feature in feature_with_na:\n",
    "    #print(f\"{feature} has {df[feature].isnull().sum()} missing values.\")\n",
    "    print(feature, np.round(df[feature].isnull().mean()*100, 5), '% missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c448063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4662.000000</td>\n",
       "      <td>4637.000000</td>\n",
       "      <td>4843.000000</td>\n",
       "      <td>4862.000000</td>\n",
       "      <td>4748.000000</td>\n",
       "      <td>4822.000000</td>\n",
       "      <td>4655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.622265</td>\n",
       "      <td>15.490835</td>\n",
       "      <td>3.708445</td>\n",
       "      <td>3.581037</td>\n",
       "      <td>3.236521</td>\n",
       "      <td>1.187267</td>\n",
       "      <td>23619.853491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.316387</td>\n",
       "      <td>8.519643</td>\n",
       "      <td>1.002509</td>\n",
       "      <td>0.798009</td>\n",
       "      <td>1.849019</td>\n",
       "      <td>0.857861</td>\n",
       "      <td>5380.698361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>98678.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  DurationOfPitch  NumberOfFollowups  PreferredPropertyStar  \\\n",
       "count  4662.000000      4637.000000        4843.000000            4862.000000   \n",
       "mean     37.622265        15.490835           3.708445               3.581037   \n",
       "std       9.316387         8.519643           1.002509               0.798009   \n",
       "min      18.000000         5.000000           1.000000               3.000000   \n",
       "25%      31.000000         9.000000           3.000000               3.000000   \n",
       "50%      36.000000        13.000000           4.000000               3.000000   \n",
       "75%      44.000000        20.000000           4.000000               4.000000   \n",
       "max      61.000000       127.000000           6.000000               5.000000   \n",
       "\n",
       "       NumberOfTrips  NumberOfChildrenVisiting  MonthlyIncome  \n",
       "count    4748.000000               4822.000000    4655.000000  \n",
       "mean        3.236521                  1.187267   23619.853491  \n",
       "std         1.849019                  0.857861    5380.698361  \n",
       "min         1.000000                  0.000000    1000.000000  \n",
       "25%         2.000000                  1.000000   20346.000000  \n",
       "50%         3.000000                  1.000000   22347.000000  \n",
       "75%         4.000000                  2.000000   25571.000000  \n",
       "max        22.000000                  3.000000   98678.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical summary of numerical columns\n",
    "df[feature_with_na].select_dtypes(exclude='object').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0f5a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuar\\AppData\\Local\\Temp\\ipykernel_55592\\3353223408.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.Age.fillna(df.Age.median(), inplace=True)\n",
      "C:\\Users\\stuar\\AppData\\Local\\Temp\\ipykernel_55592\\3353223408.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.TypeofContact.fillna(df.TypeofContact.mode()[0], inplace=True)\n",
      "C:\\Users\\stuar\\AppData\\Local\\Temp\\ipykernel_55592\\3353223408.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.DurationOfPitch.fillna(df.DurationOfPitch.median(), inplace=True)\n",
      "C:\\Users\\stuar\\AppData\\Local\\Temp\\ipykernel_55592\\3353223408.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfFollowups.fillna(df.NumberOfFollowups.mode()[0], inplace=True)\n",
      "C:\\Users\\stuar\\AppData\\Local\\Temp\\ipykernel_55592\\3353223408.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.mode()[0], inplace=True)\n",
      "C:\\Users\\stuar\\AppData\\Local\\Temp\\ipykernel_55592\\3353223408.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfTrips.fillna(df.NumberOfTrips.median(), inplace=True)\n",
      "C:\\Users\\stuar\\AppData\\Local\\Temp\\ipykernel_55592\\3353223408.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.mode()[0], inplace=True)\n",
      "C:\\Users\\stuar\\AppData\\Local\\Temp\\ipykernel_55592\\3353223408.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.MonthlyIncome.fillna(df.MonthlyIncome.median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.Age.fillna(df.Age.median(), inplace=True)\n",
    "df.TypeofContact.fillna(df.TypeofContact.mode()[0], inplace=True)\n",
    "df.DurationOfPitch.fillna(df.DurationOfPitch.median(), inplace=True)\n",
    "df.NumberOfFollowups.fillna(df.NumberOfFollowups.mode()[0], inplace=True)\n",
    "df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.mode()[0], inplace=True)\n",
    "df.NumberOfTrips.fillna(df.NumberOfTrips.median(), inplace=True)\n",
    "df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.mode()[0], inplace=True)\n",
    "df.MonthlyIncome.fillna(df.MonthlyIncome.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f86dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                  0\n",
       "ProdTaken                   0\n",
       "Age                         0\n",
       "TypeofContact               0\n",
       "CityTier                    0\n",
       "DurationOfPitch             0\n",
       "Occupation                  0\n",
       "Gender                      0\n",
       "NumberOfPersonVisiting      0\n",
       "NumberOfFollowups           0\n",
       "ProductPitched              0\n",
       "PreferredPropertyStar       0\n",
       "MaritalStatus               0\n",
       "NumberOfTrips               0\n",
       "Passport                    0\n",
       "PitchSatisfactionScore      0\n",
       "OwnCar                      0\n",
       "NumberOfChildrenVisiting    0\n",
       "Designation                 0\n",
       "MonthlyIncome               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7934b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['CustomerID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12894110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for feature extraction\n",
    "df['TotalVisiting'] = df.NumberOfChildrenVisiting + df.NumberOfPersonVisiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee2cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['NumberOfChildrenVisiting', 'NumberOfPersonVisiting'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4496fb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# get all numerical columns\n",
    "numerical_cols = [feature for feature in df.columns if df[feature].dtype!= 'O']\n",
    "print(len(numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8fa3674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# get all numerical columns\n",
    "categorical_cols = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print(len(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5399c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# discrete features - also knowns as categorical features\n",
    "# are those features which have a limited number of unique values\n",
    "discrete_features = [feature for feature in numerical_cols if len(df[feature].unique()) < 25]\n",
    "print(len(discrete_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd5a67c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# continuous features - are those features which have a large number of unique values\n",
    "continuous_features = [feature for feature in numerical_cols if feature not in discrete_features]\n",
    "print(len(continuous_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03ab34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['ProdTaken'], axis=1)\n",
    "y = df['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "514a982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3910, 17), (978, 17), (3910,), (978,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1077b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features: Index(['TypeofContact', 'Occupation', 'Gender', 'ProductPitched',\n",
      "       'MaritalStatus', 'Designation'],\n",
      "      dtype='object')\n",
      "Numerical Features: Index(['Age', 'CityTier', 'DurationOfPitch', 'NumberOfFollowups',\n",
      "       'PreferredPropertyStar', 'NumberOfTrips', 'Passport',\n",
      "       'PitchSatisfactionScore', 'OwnCar', 'MonthlyIncome', 'TotalVisiting'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_features = X.select_dtypes(include='object').columns\n",
    "num_features = X.select_dtypes(exclude='object').columns\n",
    "print(\"Categorical Features:\", cat_features)\n",
    "print(\"Numerical Features:\", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f65553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for Categorical Features and Standardization for Numerical Features\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac875676",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "    (\"OneHotEncoder\", categorical_transformer, cat_features),\n",
    "    (\"StandardScaler\", numeric_transformer, num_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a042dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afcf24c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3995    0\n",
       "2610    0\n",
       "3083    0\n",
       "3973    0\n",
       "4044    0\n",
       "       ..\n",
       "4426    0\n",
       "466     0\n",
       "3092    0\n",
       "3772    0\n",
       "860     1\n",
       "Name: ProdTaken, Length: 3910, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaa4ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "068c7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "168791d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Training Set Performance:\n",
      "Training Accuracy: 0.8460358056265984\n",
      "Training F1 Score: 0.8202118738880438\n",
      "Training Recall: 0.30315500685871055\n",
      "Training Precision: 0.7015873015873015\n",
      "Training ROC AUC: 0.6368022755136056\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.83640081799591\n",
      "Test F1 Score: 0.8086633047343356\n",
      "Test Recall: 0.2931937172774869\n",
      "Test Precision: 0.691358024691358\n",
      "Test ROC AUC: 0.630713758257549\n",
      "--------------------------------------------------\n",
      "Model: Random Forest\n",
      "Training Set Performance:\n",
      "Training Accuracy: 1.0\n",
      "Training F1 Score: 1.0\n",
      "Training Recall: 1.0\n",
      "Training Precision: 1.0\n",
      "Training ROC AUC: 1.0\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.9274028629856851\n",
      "Test F1 Score: 0.9213994793886622\n",
      "Test Recall: 0.643979057591623\n",
      "Test Precision: 0.9761904761904762\n",
      "Test ROC AUC: 0.8200835567500682\n",
      "--------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Training Set Performance:\n",
      "Training Accuracy: 1.0\n",
      "Training F1 Score: 1.0\n",
      "Training Recall: 1.0\n",
      "Training Precision: 1.0\n",
      "Training ROC AUC: 1.0\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.9192229038854806\n",
      "Test F1 Score: 0.9189800386179093\n",
      "Test Recall: 0.7853403141361257\n",
      "Test Precision: 0.7978723404255319\n",
      "Test ROC AUC: 0.8685278444886473\n",
      "--------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Training Set Performance:\n",
      "Training Accuracy: 0.8938618925831202\n",
      "Training F1 Score: 0.8819459590926597\n",
      "Training Recall: 0.5020576131687243\n",
      "Training Precision: 0.8755980861244019\n",
      "Training ROC AUC: 0.7428552762479901\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.8588957055214724\n",
      "Test F1 Score: 0.8398442289113494\n",
      "Test Recall: 0.39267015706806285\n",
      "Test Precision: 0.7731958762886598\n",
      "Test ROC AUC: 0.6823579501985804\n",
      "--------------------------------------------------\n",
      "Model: AdaBoost\n",
      "Training Set Performance:\n",
      "Training Accuracy: 0.8478260869565217\n",
      "Training F1 Score: 0.8146439190446891\n",
      "Training Recall: 0.2551440329218107\n",
      "Training Precision: 0.7815126050420168\n",
      "Training ROC AUC: 0.6193984861245332\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.8353783231083844\n",
      "Test F1 Score: 0.7987434557925993\n",
      "Test Recall: 0.2356020942408377\n",
      "Test Precision: 0.75\n",
      "Test ROC AUC: 0.6082711868917022\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    model_train_recall = recall_score(y_train, y_train_pred)\n",
    "    model_train_precision = precision_score(y_train, y_train_pred)\n",
    "    model_train_roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "    # test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    model_test_recall = recall_score(y_test, y_test_pred)\n",
    "    model_test_precision = precision_score(y_test, y_test_pred)\n",
    "    model_test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Model: {list(models.keys())[i]}\")\n",
    "    print(\"Training Set Performance:\")\n",
    "    print(f\"Training Accuracy: {model_train_accuracy}\")\n",
    "    print(f\"Training F1 Score: {model_train_f1}\")\n",
    "    print(f\"Training Recall: {model_train_recall}\")\n",
    "    print(f\"Training Precision: {model_train_precision}\")\n",
    "    print(f\"Training ROC AUC: {model_train_roc_auc}\")\n",
    "\n",
    "    print(\"Test Set Performance:\")\n",
    "    print(f\"Test Accuracy: {model_test_accuracy}\")\n",
    "    print(f\"Test F1 Score: {model_test_f1}\")\n",
    "    print(f\"Test Recall: {model_test_recall}\")\n",
    "    print(f\"Test Precision: {model_test_precision}\")\n",
    "    print(f\"Test ROC AUC: {model_test_roc_auc}\")\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55e76ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter Tuning using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_params = {\n",
    "    \"max_depth\": [5, 8, 15, None, 10],\n",
    "    \"max_features\": [5, 7, \"auto\", 8],\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"min_samples_split\": [2, 8, 15, 20]\n",
    "}\n",
    "\n",
    "gradient_params = {\n",
    "    \"loss\": ['log_loss', 'deviance', 'exponential'],\n",
    "    \"criterion\": ['friedman_mse', 'squared_error', 'mse'],\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [5, 8, 15, None, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2040d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [5, 8, 15, None, 10],\n",
       " 'max_features': [5, 7, 'auto', 8],\n",
       " 'n_estimators': [100, 200, 500, 1000],\n",
       " 'min_samples_split': [2, 8, 15, 20]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d899f83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': ['log_loss', 'deviance', 'exponential'],\n",
       " 'criterion': ['friedman_mse', 'squared_error', 'mse'],\n",
       " 'n_estimators': [100, 200, 500],\n",
       " 'max_depth': [5, 8, 15, None, 10]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4edf6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model list for hyperparameter tuning\n",
    "randomcv_models = [\n",
    "    (\"RF\", RandomForestClassifier(), rf_params),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(), gradient_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1dcf13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RF',\n",
       "  RandomForestClassifier(),\n",
       "  {'max_depth': [5, 8, 15, None, 10],\n",
       "   'max_features': [5, 7, 'auto', 8],\n",
       "   'n_estimators': [100, 200, 500, 1000],\n",
       "   'min_samples_split': [2, 8, 15, 20]}),\n",
       " ('Gradient Boosting',\n",
       "  GradientBoostingClassifier(),\n",
       "  {'loss': ['log_loss', 'deviance', 'exponential'],\n",
       "   'criterion': ['friedman_mse', 'squared_error', 'mse'],\n",
       "   'n_estimators': [100, 200, 500],\n",
       "   'max_depth': [5, 8, 15, None, 10]})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomcv_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e13b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "69 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "47 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.90869642        nan        nan 0.89104936 0.85626747\n",
      " 0.91227692 0.87595913 0.86342827 0.84117743 0.84322458 0.8542213\n",
      " 0.87340152 0.87186699 0.84194489 0.85959136        nan 0.85933613\n",
      " 0.91074181 0.8422011  0.86419475        nan 0.8708443  0.87314531\n",
      "        nan        nan        nan 0.87212281 0.84501453        nan\n",
      "        nan 0.86751923        nan 0.88900339 0.869565   0.85038479\n",
      "        nan        nan 0.8721234  0.89181682        nan 0.86956579\n",
      " 0.86521803 0.86751923 0.87416898 0.8841438  0.86163733 0.86342748\n",
      " 0.91278856 0.85345384 0.86854251 0.83376101        nan 0.86572967\n",
      " 0.88465524 0.8457816  0.88363294        nan 0.9120215         nan\n",
      " 0.88516688 0.89053753 0.88209802 0.83324898 0.86752041 0.8347835\n",
      " 0.91074298        nan 0.87314589 0.89258252 0.91509055 0.86803087\n",
      " 0.8900255         nan 0.87058809 0.86521783 0.84245594 0.86752001\n",
      " 0.87416898 0.88823574 0.84271196 0.87544788 0.9145793  0.86879853\n",
      "        nan 0.89002589 0.87902799        nan 0.86189315 0.87033227\n",
      "        nan 0.86061405 0.83452788 0.86112687 0.88874698 0.86675177\n",
      " 0.87493605 0.86879872 0.86496299        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "168 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "44 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "66 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'friedman_mse', 'squared_error'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mse' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\stuar\\Desktop\\Data Science Learning\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.91559905 0.89872239 0.884914   0.92327482        nan 0.91739293\n",
      " 0.92787821 0.92711016        nan        nan 0.91994858 0.92378745\n",
      "        nan        nan 0.89232709        nan 0.92608669 0.88465799\n",
      " 0.90690549 0.92097401 0.88312385        nan        nan        nan\n",
      "        nan 0.92608767 0.92046179        nan 0.88568028        nan\n",
      " 0.92353104        nan        nan        nan        nan 0.89233239\n",
      " 0.89181584        nan        nan        nan        nan 0.88133193\n",
      "        nan 0.88542388        nan 0.91969393        nan        nan\n",
      "        nan        nan 0.88516845        nan        nan 0.89590857\n",
      "        nan        nan 0.91508761 0.92736578        nan 0.92378686\n",
      "        nan 0.92480837        nan 0.92711075        nan        nan\n",
      " 0.88516923 0.88030944        nan 0.88414517        nan        nan\n",
      "        nan        nan 0.8810771  0.88337791        nan 0.88491224\n",
      "        nan        nan 0.88363294 0.92404307        nan        nan\n",
      "        nan        nan        nan        nan 0.92480935        nan\n",
      " 0.92071878        nan 0.88184377 0.88696076        nan        nan\n",
      "        nan 0.92660029        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RF: {'n_estimators': 500, 'min_samples_split': 2, 'max_features': 8, 'max_depth': None}\n",
      "Best parameters for Gradient Boosting: {'n_estimators': 500, 'max_depth': 10, 'loss': 'exponential', 'criterion': 'squared_error'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                param_distributions=params,\n",
    "                                n_iter=100,\n",
    "                                cv=3,\n",
    "                                verbose=2,\n",
    "                                n_jobs=-1,\n",
    "                                )\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name, params in model_param.items():\n",
    "    print(f\"Best parameters for {model_name}: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ccef420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remodeling using hyperparameter\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(**model_param['RF']),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(**model_param['Gradient Boosting'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dde813c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Training Set Performance:\n",
      "Training Accuracy: 1.0\n",
      "Training F1 Score: 1.0\n",
      "Training Recall: 1.0\n",
      "Training Precision: 1.0\n",
      "Training ROC AUC: 1.0\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.9355828220858896\n",
      "Test F1 Score: 0.9314434086004779\n",
      "Test Recall: 0.6963350785340314\n",
      "Test Precision: 0.9637681159420289\n",
      "Test ROC AUC: 0.8449909191907768\n",
      "--------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Training Set Performance:\n",
      "Training Accuracy: 1.0\n",
      "Training F1 Score: 1.0\n",
      "Training Recall: 1.0\n",
      "Training Precision: 1.0\n",
      "Training ROC AUC: 1.0\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.9591002044989775\n",
      "Test F1 Score: 0.957637969504513\n",
      "Test Recall: 0.8115183246073299\n",
      "Test Precision: 0.9748427672955975\n",
      "Test ROC AUC: 0.9032178662426738\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    model_train_recall = recall_score(y_train, y_train_pred)\n",
    "    model_train_precision = precision_score(y_train, y_train_pred)\n",
    "    model_train_roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "    # test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    model_test_recall = recall_score(y_test, y_test_pred)\n",
    "    model_test_precision = precision_score(y_test, y_test_pred)\n",
    "    model_test_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Model: {list(models.keys())[i]}\")\n",
    "    print(\"Training Set Performance:\")\n",
    "    print(f\"Training Accuracy: {model_train_accuracy}\")\n",
    "    print(f\"Training F1 Score: {model_train_f1}\")\n",
    "    print(f\"Training Recall: {model_train_recall}\")\n",
    "    print(f\"Training Precision: {model_train_precision}\")\n",
    "    print(f\"Training ROC AUC: {model_train_roc_auc}\")\n",
    "\n",
    "    print(\"Test Set Performance:\")\n",
    "    print(f\"Test Accuracy: {model_test_accuracy}\")\n",
    "    print(f\"Test F1 Score: {model_test_f1}\")\n",
    "    print(f\"Test Recall: {model_test_recall}\")\n",
    "    print(f\"Test Precision: {model_test_precision}\")\n",
    "    print(f\"Test ROC AUC: {model_test_roc_auc}\")\n",
    "    print(\"-\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
